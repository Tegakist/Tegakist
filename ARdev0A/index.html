<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAR with ORB/SIFT</title>
    <style>
        body { margin: 0; }
        canvas { display: block; }
    </style>
    <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        async function loadDescriptors() {
            try {
                const response = await fetch('descriptors.npy');
                const buffer = await response.arrayBuffer();
                return new Float32Array(buffer);
            } catch (error) {
                console.error('Error loading descriptors:', error);
                return null;
            }
        }

        async function init() {
            const descriptors = await loadDescriptors();
            if (!descriptors) return;

            startVideoProcessing(descriptors);
        }

        function startVideoProcessing(descriptors) {
            const video = document.createElement('video');
            video.setAttribute('autoplay', '');
            video.setAttribute('muted', '');
            video.setAttribute('playsinline', '');
            document.body.appendChild(video);

            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        video.play();
                        detectAndMatchFeatures(video, descriptors);
                    };
                })
                .catch(err => {
                    console.error('Error accessing camera:', err);
                });
        }

        function detectAndMatchFeatures(video, descriptors) {
            const src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
            const gray = new cv.Mat();
            const cap = new cv.VideoCapture(video);

            function processVideo() {
                try {
                    cap.read(src);
                    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

                    const orb = new cv.ORB();
                    const keypoints = new cv.KeyPointVector();
                    const descriptor = new cv.Mat();
                    orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptor);

                    const bf = new cv.BFMatcher(cv.NORM_HAMMING, true);
                    const matches = new cv.DMatchVector();
                    bf.match(descriptor, descriptors, matches);

                    console.log('Matches:', matches.size());

                    descriptor.delete();
                    keypoints.delete();
                    matches.delete();

                    requestAnimationFrame(processVideo);
                } catch (error) {
                    console.error('Error processing video frame:', error);
                }
            }

            requestAnimationFrame(processVideo);
        }

        cv['onRuntimeInitialized'] = () => {
            console.log('OpenCV.js initialized');
            init();
        };
    </script>
</body>
</html>
